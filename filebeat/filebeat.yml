filebeat:
   inputs:  #Inputs specify how Filebeat locates and processes input data.
      - type: filestream
        id: ${APPNAME}-express  #Each filestream input must have a unique ID to allow tracking the state of files.
        fields_under_root: true
        encoding: utf-8
        fields:
           event.dataset: ${APPNAME}-express
           service_name: ${APPNAME}-express
        paths:
            - /var/log/${APPNAME}-express/*.log
        multiline:
          pattern: '^\['
          negate: true
          match: after
      
      - type: filestream
        id: ${APPNAME}-nginx  #Each filestream input must have a unique ID to allow tracking the state of files.
        fields_under_root: true
        encoding: utf-8
        fields:
           event.dataset: ${APPNAME}-nginx
           service_name: ${APPNAME}-nginx
        paths:
            - /var/log/${APPNAME}-nginx/*.log
        multiline:
          pattern: '^\['
          negate: true
          match: after

#The input in this example harvests all files in the path /var/log/nginx/*.log,
# which means that Filebeat will harvest all files in the directory /var/log/ that end with .log
# When fields_under_root: true is enabled in your filebeat.yml configuration, any custom fields 
# defined within an input or prospector will be added as top-level fields in the output document.
#

setup:
   kibana:
      host: "kibana:5601"

output.logstash:
      hosts: 'logstash:5001'

monitoring:
  enabled: true
  elasticsearch:
    hosts: ["http://elasticsearch:9200"]

exclude_files: ['*.gz', '*.tmp']

processors:
  - add_host_metadata: ~
  - add_cloud_metadata: ~
  - drop_fields:
      fields: ["host", "agent"]
